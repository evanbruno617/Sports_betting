{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dfa0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d5dbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 107.0.5304\n",
      "Get LATEST chromedriver version for 107.0.5304 google-chrome\n",
      "Driver [/Users/evanbruno/.wdm/drivers/chromedriver/mac64/107.0.5304.62/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "# open browser\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8d252bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit nba page \n",
    "url = 'https://www.nba.com/stats/teams/boxscores/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "359ab36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit nba page \n",
    "url = 'https://www.nba.com/stats/teams/boxscores/?Season=2021-22'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6f773d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nba.com/stats/teams/boxscores?SeasonType=Pre+Season'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30e1f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url used for entering each games data\n",
    "revise_url = \"https://www.nba.com/game/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f569f73f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "flag = ''\n",
    "# number of pages to click through\n",
    "for pages in range(0, 2):\n",
    "    \n",
    "    #sleep\n",
    "    time.sleep(random.randint(1, 5))\n",
    "    \n",
    "    html = browser.html\n",
    "    test = soup(html, 'html.parser')\n",
    "    \n",
    "    #finds all the hyperlinks on page \n",
    "    find = test.find_all(\"tbody\")[2].find_all(\"a\")\n",
    "\n",
    "    links = []\n",
    "    # iterates through hyperlinks to find ones linked to game scores\n",
    "    for link in find:\n",
    "        if \"/game/\" in link.get('href'):\n",
    "            links.append(link.get('href')[6:])\n",
    "    \n",
    "    # get dates to name each csv file \n",
    "    test_date = []\n",
    "    names = []\n",
    "    for date in find:\n",
    "        if \"/games?date\" in date.get('href'):\n",
    "            test_date.append(date.get_text())\n",
    "            names.append(f\"{date.get_text()[:2]}-{date.get_text()[3:5]}\")\n",
    "            \n",
    "    #iterate through each game link \n",
    "    for y in range(len(links)):\n",
    "        \n",
    "        if flag == 'break':\n",
    "            break\n",
    "        \n",
    "        #used to make sure don't click the same game link twice\n",
    "        \n",
    "        \n",
    "        if (y % 2) == 0:\n",
    "            print(y)\n",
    "            \n",
    "            #visit game link \n",
    "            browser.visit(f\"{revise_url}{links[y]}\")\n",
    "            time.sleep(random.randint(5, 10))\n",
    "\n",
    "            #finds box score \n",
    "            try:\n",
    "                browser.find_by_id(\"box-score\").click()\n",
    "            except:\n",
    "                browser.visit(f\"{revise_url}{links[y]}\")\n",
    "                browser.find_by_id(\"box-score\").click()\n",
    "    \n",
    "            time.sleep(random.randint(1, 3))\n",
    "            html = browser.html\n",
    "            test2 = soup(html, 'html.parser')\n",
    "            \n",
    "            #obtain column names\n",
    "            column = []\n",
    "            for i in range(1, len(test2.find(class_=\"StatsTable_table__Ejk5X\").find_all(\"th\"))):\n",
    "                column.append(test2.find(class_=\"StatsTableHead_thead__omZuF\").find_all(\"th\")[i].get_text())\n",
    "            \n",
    "            #iterate through both teams box scores\n",
    "            for i in range(2):\n",
    "                stats = {}\n",
    "                #get team name\n",
    "                team_name = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[i].get_text()\n",
    "                \n",
    "                if i == 0:\n",
    "                    opponent = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[1].get_text()\n",
    "                else:\n",
    "                    opponent = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[0].get_text()\n",
    "    \n",
    "                stats[\"Opponent\"] = []\n",
    "                #iterate through rows\n",
    "                for t in range(len(test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\"))):\n",
    "        \n",
    "                    #iterate through columns to get data \n",
    "                    for x in range(1, 21):\n",
    "                    \n",
    "                        # comparison used to avoid hitting errors in obtaining wrong data \n",
    "                        if test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[0].get_text() == \"TOTALS\":\n",
    "                            break\n",
    "                        \n",
    "                        if x == 1:\n",
    "                            #adds name of player to dictionary\n",
    "                            name = (test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find(\"td\").find(class_=\"GameBoxscoreTablePlayer_gbpNameFull__cf_sn\").get_text())\n",
    "                            stats[name] = []\n",
    "                        \n",
    "                        #append nan if player does not play  \n",
    "                        if test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[1].get_text() in (\"DNP - Coach's Decision\", \"DNP - Injury/Illness\", \"NWT - Personal\", \"DND - Injury/Illness\", \"DNP - League Suspension\", \"DNP - Personal\", \"DND - Rest\", \"DND_LEAGUE_SUSPENSION\", \"NWT-Return to Competition Reconditioning\", \"NWT - Not With Team\", \"DND - Personal\", \"DND-Return to Competition Reconditioning\", \"DNP - Rest\", \"DND - Coach's Decision\", \"NWT - League Suspension\", \"NWT - Injury/Illness\", \"NWT - Rest\", \"NWT_RETURN_TO_COMPETITION_RECONDITIONING\", \"NWT - Health and Safety Protocols\", \"NP - Health and Safety Protocols\", \"DNP - Health and Safety Protocols\", \"DND - Health and Safety Protocols\"):\n",
    "                            stats[name].append(np.nan)\n",
    "                        \n",
    "                        #append stats for each player \n",
    "                        else:\n",
    "                            stats[name].append(test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[x].get_text())\n",
    "                            \n",
    "                # creates dataframe \n",
    "                team_data = pd.DataFrame.from_dict(stats, orient='index', columns = column)\n",
    "                #creates data column\n",
    "                team_data[\"Date\"] = test_date[y]\n",
    "                team_data[\"Opponent\"] = opponent\n",
    "                team_data = team_data.dropna()\n",
    "                \n",
    "                #creates float datatype for each column\n",
    "                for x in ['FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%',\n",
    "       'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PTS', '+/-']:\n",
    "                    team_data[x] = team_data[x].astype(float)\n",
    "                    \n",
    "                # calculates players score according to draftkings\n",
    "                team_data[\"Score\"] = ((team_data[\"FGM\"] - team_data[\"3PM\"]) * 2) * 1 + (team_data[\"3PM\"] * 0.5) + team_data[\"3PM\"] * 3 + team_data[\"REB\"] * 1.25 + team_data[\"AST\"] * 1.5 + team_data[\"STL\"] * 2 + team_data[\"BLK\"] * 2 - team_data[\"TO\"] * 0.5 + team_data[\"FTM\"]\n",
    "          \n",
    "                #creates folder for team\n",
    "                mypath = team_name\n",
    "                if not os.path.isdir(mypath):\n",
    "                    os.makedirs(mypath)\n",
    "                # converts dataframe to csv\n",
    "        \n",
    "                #obtain list of dates\n",
    "                directory = team_name\n",
    "                list_dates = []\n",
    "                for filename in os.listdir(directory):\n",
    "                    if filename.endswith(\".csv\"):\n",
    "                        list_dates.append(filename)\n",
    "                        \n",
    "\n",
    "                \n",
    "                if f\"{names[y]}.csv\" in list_dates:\n",
    "                    print(\"Finished\")\n",
    "                    browser.quit()\n",
    "                    flag = 'break'\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    team_data.to_csv(f\"{mypath}/{names[y]}.csv\", index=True)\n",
    "                    \n",
    "    if flag == 'break':\n",
    "        break\n",
    "    \n",
    "    #revisit url\n",
    "    browser.visit(url)\n",
    "    \n",
    "   #click to next page\n",
    "    browser.find_option_by_text(f'{pages}').first.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39cfaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(f\"{revise_url}{links[y]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b99e3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quit browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if f\"{names[y]}.csv\" in list_dates:\n",
    "                    print(\"Finished\")\n",
    "                    browser.quit()\n",
    "                    flag = 'break'\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d99de",
   "metadata": {},
   "source": [
    "## Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "51bba992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "flag = ''\n",
    "# number of pages to click through\n",
    "for pages in range(47, 51):\n",
    "    \n",
    "    #sleep\n",
    "    time.sleep(random.randint(1, 5))\n",
    "    \n",
    "    html = browser.html\n",
    "    test = soup(html, 'html.parser')\n",
    "    \n",
    "    #finds all the hyperlinks on page \n",
    "    find = test.find_all(\"tbody\")[2].find_all(\"a\")\n",
    "\n",
    "    links = []\n",
    "    # iterates through hyperlinks to find ones linked to game scores\n",
    "    for link in find:\n",
    "        if \"/game/\" in link.get('href'):\n",
    "            links.append(link.get('href')[6:])\n",
    "    \n",
    "    # get dates to name each csv file \n",
    "    test_date = []\n",
    "    names = []\n",
    "    for date in find:\n",
    "        if \"/games?date\" in date.get('href'):\n",
    "            test_date.append(date.get_text())\n",
    "            names.append(f\"{date.get_text()[:2]}-{date.get_text()[3:5]}\")\n",
    "            \n",
    "    #iterate through each game link \n",
    "    for y in range(len(links)):\n",
    "        \n",
    "        if flag == 'break':\n",
    "            break\n",
    "        \n",
    "        #used to make sure don't click the same game link twice\n",
    "        \n",
    "        \n",
    "        if (y % 2) == 0:\n",
    "            print(y)\n",
    "            #visit game link \n",
    "            browser.visit(f\"{revise_url}{links[y]}\")\n",
    "            time.sleep(random.randint(5, 10))\n",
    "            #finds box score \n",
    "            try: \n",
    "                browser.find_by_id(\"box-score\").click()\n",
    "            except:\n",
    "                browser.visit(f\"{revise_url}{links[y]}\")\n",
    "                browser.find_by_id(\"box-score\").click()\n",
    "    \n",
    "            time.sleep(random.randint(1, 3))\n",
    "            html = browser.html\n",
    "            test2 = soup(html, 'html.parser')\n",
    "            \n",
    "            #obtain column names\n",
    "            column = []\n",
    "            for i in range(1, len(test2.find(class_=\"StatsTable_table__Ejk5X\").find_all(\"th\"))):\n",
    "                column.append(test2.find(class_=\"StatsTableHead_thead__omZuF\").find_all(\"th\")[i].get_text())\n",
    "            \n",
    "            #iterate through both teams box scores\n",
    "            for i in range(2):\n",
    "                stats = {}\n",
    "                #get team name\n",
    "                team_name = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[i].get_text()\n",
    "                \n",
    "                if i == 0:\n",
    "                    opponent = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[1].get_text()\n",
    "                else:\n",
    "                    opponent = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[0].get_text()\n",
    "    \n",
    "                stats[\"Opponent\"] = []\n",
    "                #iterate through rows\n",
    "                for t in range(len(test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\"))):\n",
    "        \n",
    "                    #iterate through columns to get data \n",
    "                    for x in range(1, 21):\n",
    "                    \n",
    "                        # comparison used to avoid hitting errors in obtaining wrong data \n",
    "                        if test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[0].get_text() == \"TOTALS\":\n",
    "                            break\n",
    "                        \n",
    "                        if x == 1:\n",
    "                            #adds name of player to dictionary\n",
    "                            name = (test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find(\"td\").find(class_=\"GameBoxscoreTablePlayer_gbpNameFull__cf_sn\").get_text())\n",
    "                            stats[name] = []\n",
    "                        \n",
    "                        #append nan if player does not play  \n",
    "                        if test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[1].get_text() in (\"DNP - Coach's Decision\", \"DNP - Injury/Illness\", \"NWT - Personal\", \"DND - Injury/Illness\", \"DNP - League Suspension\", \"DNP - Personal\", \"DND - Rest\", \"DND_LEAGUE_SUSPENSION\", \"NWT-Return to Competition Reconditioning\", \"NWT - Not With Team\", \"DND - Personal\", \"DND-Return to Competition Reconditioning\", \"DNP - Rest\", \"DND - Coach's Decision\", \"NWT - League Suspension\", \"NWT - Injury/Illness\", \"NWT - Rest\", \"NWT_RETURN_TO_COMPETITION_RECONDITIONING\", \"NWT - Health and Safety Protocols\", \"NP - Health and Safety Protocols\", \"DNP - Health and Safety Protocols\", \"DND - Health and Safety Protocols\"):\n",
    "                            stats[name].append(np.nan)\n",
    "                        \n",
    "                        #append stats for each player \n",
    "                        else:\n",
    "                            stats[name].append(test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[x].get_text())\n",
    "                            \n",
    "                # creates dataframe \n",
    "                team_data = pd.DataFrame.from_dict(stats, orient='index', columns = column)\n",
    "                #creates data column\n",
    "                team_data[\"Date\"] = test_date[y]\n",
    "                team_data[\"Opponent\"] = opponent\n",
    "                team_data = team_data.dropna()\n",
    "                \n",
    "                #creates float datatype for each column\n",
    "                for x in ['FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%',\n",
    "       'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PTS', '+/-']:\n",
    "                    team_data[x] = team_data[x].astype(float)\n",
    "                    \n",
    "                # calculates players score according to draftkings\n",
    "                team_data[\"Score\"] = ((team_data[\"FGM\"] - team_data[\"3PM\"]) * 2) * 1 + (team_data[\"3PM\"] * 0.5) + team_data[\"3PM\"] * 3 + team_data[\"REB\"] * 1.25 + team_data[\"AST\"] * 1.5 + team_data[\"STL\"] * 2 + team_data[\"BLK\"] * 2 - team_data[\"TO\"] * 0.5 + team_data[\"FTM\"]\n",
    "          \n",
    "                #creates folder for team\n",
    "                mypath = f\"Historical/{team_name}\"\n",
    "                if not os.path.isdir(mypath):\n",
    "                    os.makedirs(mypath)\n",
    "                # converts dataframe to csv\n",
    "        \n",
    "                #obtain list of dates\n",
    "                directory = team_name\n",
    "                list_dates = []\n",
    "                for filename in os.listdir(directory):\n",
    "                    if filename.endswith(\".csv\"):\n",
    "                        list_dates.append(filename)\n",
    "                        \n",
    "                \n",
    "                \n",
    "                \n",
    "                else:\n",
    "                    team_data.to_csv(f\"{mypath}/{names[y]}.csv\", index=True)\n",
    "                    \n",
    "    if flag == 'break':\n",
    "        break\n",
    "    \n",
    "    #revisit url\n",
    "    browser.visit(url)\n",
    "    \n",
    "    #click to next page\n",
    "    browser.find_option_by_text(f'{pages}').first.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8e233304",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f7206ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/stats/events/?CFID=&CFPARAMS=&ContextMeasure=TOV&GameID=0022101205&PlayerID=undefined&Season=2021-22&SeasonType=Regular%20Season&TeamID=1610612751&flag=1&sct=plot&section=game'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b32dbef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "select = browser.find_by_css(\"select[class='DropDown_select__4pIg9']\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "79823709",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.find_option_by_text('20').first.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "465205d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7babbbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
