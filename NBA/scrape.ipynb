{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dfa0ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies \n",
    "import pandas as pd\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as soup\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a9d5dbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 107.0.5304\n",
      "Get LATEST chromedriver version for 107.0.5304 google-chrome\n",
      "Driver [/Users/evanbruno/.wdm/drivers/chromedriver/mac64/107.0.5304.62/chromedriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "# open browser\n",
    "executable_path = {'executable_path': ChromeDriverManager().install()}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8d252bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit nba page \n",
    "url = 'https://www.nba.com/stats/teams/boxscores/'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "359ab36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit nba page \n",
    "url = 'https://www.nba.com/stats/teams/boxscores/?Season=2021-22'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6f773d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.nba.com/stats/teams/boxscores?SeasonType=Pre+Season'\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30e1f88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url used for entering each games data\n",
    "revise_url = \"https://www.nba.com/game/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f569f73f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n"
     ]
    },
    {
     "ename": "ElementDoesNotExist",
     "evalue": "no elements could be found with option by text \"0\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/splinter/element_list.py:39\u001b[0m, in \u001b[0;36mElementList.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_container\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mElementDoesNotExist\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    132\u001b[0m  browser\u001b[38;5;241m.\u001b[39mvisit(url)\n\u001b[1;32m    134\u001b[0m \u001b[38;5;66;03m#click to next page\u001b[39;00m\n\u001b[0;32m--> 135\u001b[0m  \u001b[43mbrowser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_option_by_text\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpages\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/splinter/element_list.py:55\u001b[0m, in \u001b[0;36mElementList.first\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfirst\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;124;03m\"\"\"An alias to the first element of the list.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m        >>> assert element_list[0] == element_list.first\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/splinter/element_list.py:41\u001b[0m, in \u001b[0;36mElementList.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container[index]\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ElementDoesNotExist(\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;124mu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mno elements could be found with \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     43\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfind_by, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery\n\u001b[1;32m     44\u001b[0m         )\n\u001b[1;32m     45\u001b[0m     )\n",
      "\u001b[0;31mElementDoesNotExist\u001b[0m: no elements could be found with option by text \"0\""
     ]
    }
   ],
   "source": [
    "flag = ''\n",
    "# number of pages to click through\n",
    "for pages in range(0, 2):\n",
    "    \n",
    "    #sleep\n",
    "    time.sleep(random.randint(1, 5))\n",
    "    \n",
    "    html = browser.html\n",
    "    test = soup(html, 'html.parser')\n",
    "    \n",
    "    #finds all the hyperlinks on page \n",
    "    find = test.find_all(\"tbody\")[2].find_all(\"a\")\n",
    "\n",
    "    links = []\n",
    "    # iterates through hyperlinks to find ones linked to game scores\n",
    "    for link in find:\n",
    "        if \"/game/\" in link.get('href'):\n",
    "            links.append(link.get('href')[6:])\n",
    "    \n",
    "    # get dates to name each csv file \n",
    "    test_date = []\n",
    "    names = []\n",
    "    for date in find:\n",
    "        if \"/games?date\" in date.get('href'):\n",
    "            test_date.append(date.get_text())\n",
    "            names.append(f\"{date.get_text()[:2]}-{date.get_text()[3:5]}\")\n",
    "            \n",
    "    #iterate through each game link \n",
    "    for y in range(len(links)):\n",
    "        \n",
    "        if flag == 'break':\n",
    "            break\n",
    "        \n",
    "        #used to make sure don't click the same game link twice\n",
    "        \n",
    "        \n",
    "        if (y % 2) == 0:\n",
    "            print(y)\n",
    "            \n",
    "            #visit game link \n",
    "            browser.visit(f\"{revise_url}{links[y]}\")\n",
    "            time.sleep(random.randint(5, 10))\n",
    "\n",
    "            #finds box score \n",
    "            try:\n",
    "                browser.find_by_id(\"box-score\").click()\n",
    "            except:\n",
    "                browser.visit(f\"{revise_url}{links[y]}\")\n",
    "                browser.find_by_id(\"box-score\").click()\n",
    "    \n",
    "            time.sleep(random.randint(1, 3))\n",
    "            html = browser.html\n",
    "            test2 = soup(html, 'html.parser')\n",
    "            \n",
    "            #obtain column names\n",
    "            column = []\n",
    "            for i in range(1, len(test2.find(class_=\"StatsTable_table__Ejk5X\").find_all(\"th\"))):\n",
    "                column.append(test2.find(class_=\"StatsTableHead_thead__omZuF\").find_all(\"th\")[i].get_text())\n",
    "            \n",
    "            #iterate through both teams box scores\n",
    "            for i in range(2):\n",
    "                stats = {}\n",
    "                #get team name\n",
    "                team_name = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[i].get_text()\n",
    "                \n",
    "                if i == 0:\n",
    "                    opponent = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[1].get_text()\n",
    "                else:\n",
    "                    opponent = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[0].get_text()\n",
    "    \n",
    "                stats[\"Opponent\"] = []\n",
    "                #iterate through rows\n",
    "                for t in range(len(test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\"))):\n",
    "        \n",
    "                    #iterate through columns to get data \n",
    "                    for x in range(1, 21):\n",
    "                    \n",
    "                        # comparison used to avoid hitting errors in obtaining wrong data \n",
    "                        if test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[0].get_text() == \"TOTALS\":\n",
    "                            break\n",
    "                        \n",
    "                        if x == 1:\n",
    "                            #adds name of player to dictionary\n",
    "                            name = (test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find(\"td\").find(class_=\"GameBoxscoreTablePlayer_gbpNameFull__cf_sn\").get_text())\n",
    "                            stats[name] = []\n",
    "                        \n",
    "                        #append nan if player does not play  \n",
    "                        if test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[1].get_text() in (\"DNP - Coach's Decision\", \"DNP - Injury/Illness\", \"NWT - Personal\", \"DND - Injury/Illness\", \"DNP - League Suspension\", \"DNP - Personal\", \"DND - Rest\", \"DND_LEAGUE_SUSPENSION\", \"NWT-Return to Competition Reconditioning\", \"NWT - Not With Team\", \"DND - Personal\", \"DND-Return to Competition Reconditioning\", \"DNP - Rest\", \"DND - Coach's Decision\", \"NWT - League Suspension\", \"NWT - Injury/Illness\", \"NWT - Rest\", \"NWT_RETURN_TO_COMPETITION_RECONDITIONING\", \"NWT - Health and Safety Protocols\", \"NP - Health and Safety Protocols\", \"DNP - Health and Safety Protocols\", \"DND - Health and Safety Protocols\"):\n",
    "                            stats[name].append(np.nan)\n",
    "                        \n",
    "                        #append stats for each player \n",
    "                        else:\n",
    "                            stats[name].append(test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[x].get_text())\n",
    "                            \n",
    "                # creates dataframe \n",
    "                team_data = pd.DataFrame.from_dict(stats, orient='index', columns = column)\n",
    "                #creates data column\n",
    "                team_data[\"Date\"] = test_date[y]\n",
    "                team_data[\"Opponent\"] = opponent\n",
    "                team_data = team_data.dropna()\n",
    "                \n",
    "                #creates float datatype for each column\n",
    "                for x in ['FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%',\n",
    "       'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PTS', '+/-']:\n",
    "                    team_data[x] = team_data[x].astype(float)\n",
    "                    \n",
    "                # calculates players score according to draftkings\n",
    "                team_data[\"Score\"] = ((team_data[\"FGM\"] - team_data[\"3PM\"]) * 2) * 1 + (team_data[\"3PM\"] * 0.5) + team_data[\"3PM\"] * 3 + team_data[\"REB\"] * 1.25 + team_data[\"AST\"] * 1.5 + team_data[\"STL\"] * 2 + team_data[\"BLK\"] * 2 - team_data[\"TO\"] * 0.5 + team_data[\"FTM\"]\n",
    "          \n",
    "                #creates folder for team\n",
    "                mypath = team_name\n",
    "                if not os.path.isdir(mypath):\n",
    "                    os.makedirs(mypath)\n",
    "                # converts dataframe to csv\n",
    "        \n",
    "                #obtain list of dates\n",
    "                directory = team_name\n",
    "                list_dates = []\n",
    "                for filename in os.listdir(directory):\n",
    "                    if filename.endswith(\".csv\"):\n",
    "                        list_dates.append(filename)\n",
    "                        \n",
    "\n",
    "                \n",
    "                else:\n",
    "                    team_data.to_csv(f\"{mypath}/{names[y]}.csv\", index=True)\n",
    "                    \n",
    "    if flag == 'break':\n",
    "        break\n",
    "    \n",
    "    #revisit url\n",
    "    browser.visit(url)\n",
    "    \n",
    "   #click to next page\n",
    "    browser.find_option_by_text(f'{pages}').first.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39cfaf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.visit(f\"{revise_url}{links[y]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b99e3ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quit browser\n",
    "browser.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad40a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if f\"{names[y]}.csv\" in list_dates:\n",
    "                    print(\"Finished\")\n",
    "                    browser.quit()\n",
    "                    flag = 'break'\n",
    "                    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d99de",
   "metadata": {},
   "source": [
    "## Historical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "51bba992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n",
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n",
      "12\n",
      "14\n",
      "16\n",
      "18\n",
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n",
      "40\n",
      "42\n",
      "44\n",
      "46\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "flag = ''\n",
    "# number of pages to click through\n",
    "for pages in range(47, 51):\n",
    "    \n",
    "    #sleep\n",
    "    time.sleep(random.randint(1, 5))\n",
    "    \n",
    "    html = browser.html\n",
    "    test = soup(html, 'html.parser')\n",
    "    \n",
    "    #finds all the hyperlinks on page \n",
    "    find = test.find_all(\"tbody\")[2].find_all(\"a\")\n",
    "\n",
    "    links = []\n",
    "    # iterates through hyperlinks to find ones linked to game scores\n",
    "    for link in find:\n",
    "        if \"/game/\" in link.get('href'):\n",
    "            links.append(link.get('href')[6:])\n",
    "    \n",
    "    # get dates to name each csv file \n",
    "    test_date = []\n",
    "    names = []\n",
    "    for date in find:\n",
    "        if \"/games?date\" in date.get('href'):\n",
    "            test_date.append(date.get_text())\n",
    "            names.append(f\"{date.get_text()[:2]}-{date.get_text()[3:5]}\")\n",
    "            \n",
    "    #iterate through each game link \n",
    "    for y in range(len(links)):\n",
    "        \n",
    "        if flag == 'break':\n",
    "            break\n",
    "        \n",
    "        #used to make sure don't click the same game link twice\n",
    "        \n",
    "        \n",
    "        if (y % 2) == 0:\n",
    "            print(y)\n",
    "            #visit game link \n",
    "            browser.visit(f\"{revise_url}{links[y]}\")\n",
    "            time.sleep(random.randint(5, 10))\n",
    "            #finds box score \n",
    "            try: \n",
    "                browser.find_by_id(\"box-score\").click()\n",
    "            except:\n",
    "                browser.visit(f\"{revise_url}{links[y]}\")\n",
    "                browser.find_by_id(\"box-score\").click()\n",
    "    \n",
    "            time.sleep(random.randint(1, 3))\n",
    "            html = browser.html\n",
    "            test2 = soup(html, 'html.parser')\n",
    "            \n",
    "            #obtain column names\n",
    "            column = []\n",
    "            for i in range(1, len(test2.find(class_=\"StatsTable_table__Ejk5X\").find_all(\"th\"))):\n",
    "                column.append(test2.find(class_=\"StatsTableHead_thead__omZuF\").find_all(\"th\")[i].get_text())\n",
    "            \n",
    "            #iterate through both teams box scores\n",
    "            for i in range(2):\n",
    "                stats = {}\n",
    "                #get team name\n",
    "                team_name = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[i].get_text()\n",
    "                \n",
    "                if i == 0:\n",
    "                    opponent = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[1].get_text()\n",
    "                else:\n",
    "                    opponent = test2.find_all(class_=\"GameBoxscoreTeamHeader_gbt__b9B6g\")[0].get_text()\n",
    "    \n",
    "                stats[\"Opponent\"] = []\n",
    "                #iterate through rows\n",
    "                for t in range(len(test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\"))):\n",
    "        \n",
    "                    #iterate through columns to get data \n",
    "                    for x in range(1, 21):\n",
    "                    \n",
    "                        # comparison used to avoid hitting errors in obtaining wrong data \n",
    "                        if test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[0].get_text() == \"TOTALS\":\n",
    "                            break\n",
    "                        \n",
    "                        if x == 1:\n",
    "                            #adds name of player to dictionary\n",
    "                            name = (test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find(\"td\").find(class_=\"GameBoxscoreTablePlayer_gbpNameFull__cf_sn\").get_text())\n",
    "                            stats[name] = []\n",
    "                        \n",
    "                        #append nan if player does not play  \n",
    "                        if test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[1].get_text() in (\"DNP - Coach's Decision\", \"DNP - Injury/Illness\", \"NWT - Personal\", \"DND - Injury/Illness\", \"DNP - League Suspension\", \"DNP - Personal\", \"DND - Rest\", \"DND_LEAGUE_SUSPENSION\", \"NWT-Return to Competition Reconditioning\", \"NWT - Not With Team\", \"DND - Personal\", \"DND-Return to Competition Reconditioning\", \"DNP - Rest\", \"DND - Coach's Decision\", \"NWT - League Suspension\", \"NWT - Injury/Illness\", \"NWT - Rest\", \"NWT_RETURN_TO_COMPETITION_RECONDITIONING\", \"NWT - Health and Safety Protocols\", \"NP - Health and Safety Protocols\", \"DNP - Health and Safety Protocols\", \"DND - Health and Safety Protocols\"):\n",
    "                            stats[name].append(np.nan)\n",
    "                        \n",
    "                        #append stats for each player \n",
    "                        else:\n",
    "                            stats[name].append(test2.find_all(\"tbody\", class_=\"StatsTableBody_tbody__uvj_P\")[i].find_all(\"tr\")[t].find_all(\"td\")[x].get_text())\n",
    "                            \n",
    "                # creates dataframe \n",
    "                team_data = pd.DataFrame.from_dict(stats, orient='index', columns = column)\n",
    "                #creates data column\n",
    "                team_data[\"Date\"] = test_date[y]\n",
    "                team_data[\"Opponent\"] = opponent\n",
    "                team_data = team_data.dropna()\n",
    "                \n",
    "                #creates float datatype for each column\n",
    "                for x in ['FGM', 'FGA', 'FG%', '3PM', '3PA', '3P%', 'FTM', 'FTA', 'FT%',\n",
    "       'OREB', 'DREB', 'REB', 'AST', 'STL', 'BLK', 'TO', 'PF', 'PTS', '+/-']:\n",
    "                    team_data[x] = team_data[x].astype(float)\n",
    "                    \n",
    "                # calculates players score according to draftkings\n",
    "                team_data[\"Score\"] = ((team_data[\"FGM\"] - team_data[\"3PM\"]) * 2) * 1 + (team_data[\"3PM\"] * 0.5) + team_data[\"3PM\"] * 3 + team_data[\"REB\"] * 1.25 + team_data[\"AST\"] * 1.5 + team_data[\"STL\"] * 2 + team_data[\"BLK\"] * 2 - team_data[\"TO\"] * 0.5 + team_data[\"FTM\"]\n",
    "          \n",
    "                #creates folder for team\n",
    "                mypath = f\"Historical/{team_name}\"\n",
    "                if not os.path.isdir(mypath):\n",
    "                    os.makedirs(mypath)\n",
    "                # converts dataframe to csv\n",
    "        \n",
    "                #obtain list of dates\n",
    "                directory = team_name\n",
    "                list_dates = []\n",
    "                for filename in os.listdir(directory):\n",
    "                    if filename.endswith(\".csv\"):\n",
    "                        list_dates.append(filename)\n",
    "                        \n",
    "                \n",
    "                \n",
    "                \n",
    "                else:\n",
    "                    team_data.to_csv(f\"{mypath}/{names[y]}.csv\", index=True)\n",
    "                    \n",
    "    if flag == 'break':\n",
    "        break\n",
    "    \n",
    "    #revisit url\n",
    "    browser.visit(url)\n",
    "    \n",
    "    #click to next page\n",
    "    browser.find_option_by_text(f'{pages}').first.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "465205d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "browser.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
